{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b56a1b-85b1-47b5-aabe-1e7a6141dfbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "diffusers\n",
    "ftfy\n",
    "google-cloud-aiplatform\n",
    "gradio\n",
    "ninja\n",
    "tensorboard==1.15.0\n",
    "torch\n",
    "torchaudio\n",
    "torchvision\n",
    "torchserve\n",
    "torch-model-archiver\n",
    "torch-workflow-archiver\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dae67ef-ce1d-4ed6-99e7-2a8ccce7c624",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers (from -r requirements.txt (line 1))\n",
      "  Using cached diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting ftfy (from -r requirements.txt (line 2))\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.71.1)\n",
      "Collecting gradio (from -r requirements.txt (line 4))\n",
      "  Using cached gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ninja (from -r requirements.txt (line 5))\n",
      "  Using cached ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting tensorboard==1.15.0 (from -r requirements.txt (line 6))\n",
      "  Using cached tensorboard-1.15.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting torch (from -r requirements.txt (line 7))\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchaudio (from -r requirements.txt (line 8))\n",
      "  Using cached torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 9))\n",
      "  Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchserve (from -r requirements.txt (line 10))\n",
      "  Using cached torchserve-0.12.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting torch-model-archiver (from -r requirements.txt (line 11))\n",
      "  Using cached torch_model_archiver-0.12.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting torch-workflow-archiver (from -r requirements.txt (line 12))\n",
      "  Using cached torch_workflow_archiver-0.2.15-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 13))\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.67.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard==1.15.0->-r requirements.txt (line 6))\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.25.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard==1.15.0->-r requirements.txt (line 6))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (0.44.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 1)) (8.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 1)) (3.16.1)\n",
      "Collecting huggingface-hub>=0.23.2 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting regex!=2019.12.17 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting safetensors>=0.3.1 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 1)) (11.0.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->-r requirements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (2.36.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (1.25.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (1.10.19)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 3)) (0.16)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.115.4)\n",
      "Collecting ffmpy (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.5.0 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (2.0.3)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform->-r requirements.txt (line 3))\n",
      "  Using cached pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "Collecting pydub (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart==0.0.12 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<1.0,>=0.1.1 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.41.2)\n",
      "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 4))\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.32.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.0->gradio->-r requirements.txt (line 4)) (2024.10.0)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.5.0->gradio->-r requirements.txt (line 4))\n",
      "  Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 7)) (3.4.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 7))\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.txt (line 7))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from torchserve->-r requirements.txt (line 10)) (5.9.3)\n",
      "Collecting enum-compat (from torch-model-archiver->-r requirements.txt (line 11))\n",
      "  Using cached enum_compat-0.0.3-py3-none-any.whl.metadata (954 bytes)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers->-r requirements.txt (line 13))\n",
      "  Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (4.66.5)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (1.65.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 3)) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->-r requirements.txt (line 3)) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 4))\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 4)) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->google-cloud-aiplatform->-r requirements.txt (line 3))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3->google-cloud-aiplatform->-r requirements.txt (line 3))\n",
      "  Using cached pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers->-r requirements.txt (line 1)) (1.26.20)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 4)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 4)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 4)) (13.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 4)) (0.1.2)\n",
      "Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "Using cached diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached gradio-5.7.1-py3-none-any.whl (57.1 MB)\n",
      "Using cached gradio_client-1.5.0-py3-none-any.whl (320 kB)\n",
      "Using cached python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
      "Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "Using cached torchserve-0.12.0-py3-none-any.whl (42.2 MB)\n",
      "Using cached torch_model_archiver-0.12.0-py3-none-any.whl (16 kB)\n",
      "Using cached torch_workflow_archiver-0.2.15-py3-none-any.whl (12 kB)\n",
      "Using cached transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "Using cached httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "Using cached pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
      "Using cached safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
      "Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Using cached ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Installing collected packages: torch-workflow-archiver, pydub, mpmath, enum-compat, websockets, triton, torchserve, torch-model-archiver, tomlkit, sympy, semantic-version, safetensors, ruff, regex, python-multipart, pydantic-core, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, markupsafe, markdown, httpcore, ftfy, ffmpy, annotated-types, werkzeug, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, httpx, tokenizers, tensorboard, safehttpx, nvidia-cusolver-cu12, gradio-client, diffusers, transformers, torch, gradio, torchvision, torchaudio\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 13.1\n",
      "    Uninstalling websockets-13.1:\n",
      "      Successfully uninstalled websockets-13.1\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.19\n",
      "    Uninstalling pydantic-1.10.19:\n",
      "      Successfully uninstalled pydantic-1.10.19\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataproc-jupyter-plugin 0.1.80 requires pydantic~=1.10.0, but you have pydantic 2.10.2 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.10.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 diffusers-0.31.0 enum-compat-0.0.3 ffmpy-0.4.0 ftfy-6.3.1 gradio-5.7.1 gradio-client-1.5.0 httpcore-1.0.7 httpx-0.28.0 huggingface-hub-0.26.3 markdown-3.7 markupsafe-2.1.5 mpmath-1.3.0 ninja-1.11.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 orjson-3.10.12 pydantic-2.10.2 pydantic-core-2.27.1 pydub-0.25.1 python-multipart-0.0.12 regex-2024.11.6 ruff-0.8.1 safehttpx-0.1.1 safetensors-0.4.5 semantic-version-2.10.0 sympy-1.13.1 tensorboard-1.15.0 tokenizers-0.20.3 tomlkit-0.12.0 torch-2.5.1 torch-model-archiver-0.12.0 torch-workflow-archiver-0.2.15 torchaudio-2.5.1 torchserve-0.12.0 torchvision-0.20.1 transformers-4.46.3 triton-3.1.0 websockets-12.0 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca34130-f91f-4765-aa42-1527dad05e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"assignment1-438116\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}\n",
    "\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789f8d86-78ec-4cb8-b8a8-ba2d2e055376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from google.cloud import aiplatform\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from torch import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35a9e373-52e2-4531-b179-7835f7707bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"text-to-image-model-429503\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}/\"\n",
    "FULL_GCS_PATH = f\"{BUCKET_URI}model_artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c788682-c705-46bf-8526-77194254e5b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/optimizer.bin...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/random_states_0.pkl...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/scaler.pt...       \n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/scheduler.bin...   \n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet/config.json...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet/diffusion_pytorch_model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet_ema/config.json...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet_ema/diffusion_pytorch_model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/feature_extractor/preprocessor_config.json...\n",
      "Copying gs://text-to-image-model-429503/model/logs/text2image-fine-tune/1732728687.3225884/events.out.tfevents.1732728687.5d19749c37f3.259.1...\n",
      "Copying gs://text-to-image-model-429503/model/safety_checker/model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/scheduler/scheduler_config.json...\n",
      "Copying gs://text-to-image-model-429503/model/logs/text2image-fine-tune/1732728687.324261/hparams.yml...\n",
      "Copying gs://text-to-image-model-429503/model/text_encoder/config.json...       \n",
      "Copying gs://text-to-image-model-429503/model/model.mar...\n",
      "Copying gs://text-to-image-model-429503/model/logs/text2image-fine-tune/events.out.tfevents.1732728687.5d19749c37f3.259.0...\n",
      "Copying gs://text-to-image-model-429503/model/text_encoder/model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/model_index.json...               \n",
      "Copying gs://text-to-image-model-429503/model/safety_checker/config.json...     \n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/merges.txt...           \n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/special_tokens_map.json...\n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/tokenizer_config.json...\n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/vocab.json...           \n",
      "Copying gs://text-to-image-model-429503/model/unet/config.json...               \n",
      "Copying gs://text-to-image-model-429503/model/unet/diffusion_pytorch_model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/vae/config.json...                \n",
      "Copying gs://text-to-image-model-429503/model/vae/diffusion_pytorch_model.safetensors...\n",
      "/ [27/27 files][ 17.5 GiB/ 17.5 GiB] 100% Done  44.6 MiB/s ETA 00:00:00         \n",
      "Operation completed over 27 objects/17.5 GiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r gs://text-to-image-model-429503/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5ebd92-16cf-4408-b478-bdd2c3d777c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df9b08a-4cf4-4cfc-ba1d-00739380887a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv model model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7598d0-8b75-4931-90ca-e6fe06b3d8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile handler.py\n",
    "\n",
    "import base64\n",
    "import logging\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "model_id = '/model'\n",
    "\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.initialized = False\n",
    "    self.map_location = None\n",
    "    self.device = None\n",
    "    self.use_gpu = True\n",
    "    self.store_avg = True\n",
    "    self.pipe = None\n",
    "\n",
    "  def initialize(self, context):\n",
    "    \"\"\"Initializes the pipe.\"\"\"\n",
    "    properties = context.system_properties\n",
    "    gpu_id = properties.get('gpu_id')\n",
    "\n",
    "    self.map_location, self.device, self.use_gpu = \\\n",
    "      ('cuda', torch.device('cuda:' + str(gpu_id)),\n",
    "       True) if torch.cuda.is_available() else \\\n",
    "        ('cpu', torch.device('cpu'), False)\n",
    "\n",
    "    # Use the Euler scheduler here instead\n",
    "    scheduler = EulerDiscreteScheduler.from_pretrained(model_id,\n",
    "                                                       subfolder='scheduler')\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id,\n",
    "                                                   scheduler=scheduler,\n",
    "                                                   torch_dtype=torch.float16)\n",
    "    if torch.cuda.is_available():\n",
    "        pipe = pipe.to('cuda')\n",
    "    else:\n",
    "        pipe=pipe.to('cpu')\n",
    "    \n",
    "    # Uncomment the following line to reduce the GPU memory usage.\n",
    "    # pipe.enable_attention_slicing()\n",
    "    self.pipe = pipe\n",
    "\n",
    "    self.initialized = True\n",
    "\n",
    "  def preprocess(self, requests):\n",
    "    \"\"\"Noting to do here.\"\"\"\n",
    "    logger.info('requests: %s', requests)\n",
    "    return requests\n",
    "\n",
    "  def inference(self, preprocessed_data, *args, **kwargs):\n",
    "    \"\"\"Run the inference.\"\"\"\n",
    "    images = []\n",
    "    for pd in preprocessed_data:\n",
    "      prompt = pd['prompt']\n",
    "      images.extend(self.pipe(prompt).images)\n",
    "    return images\n",
    "\n",
    "  def postprocess(self, output_batch):\n",
    "    \"\"\"Converts the images to base64 string.\"\"\"\n",
    "    postprocessed_data = []\n",
    "    for op in output_batch:\n",
    "      fp = BytesIO()\n",
    "      op.save(fp, format='JPEG')\n",
    "      postprocessed_data.append(base64.b64encode(fp.getvalue()).decode('utf-8'))\n",
    "      fp.close()\n",
    "    return postprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acdec5c8-e58f-491f-b611-f0a769370ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\tmodel.mar\t requirements.txt  tutorials\n",
      "handler.py\tmodel_artifacts  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe4674a-c474-48c0-8be5-cbb531e9b5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torch-model-archiver \\\n",
    "  -f \\\n",
    "  --model-name sdft \\\n",
    "  --version 1.0 \\\n",
    "  --handler handler.py \\\n",
    "  --export-path model_artifacts/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd1fc465-9543-454d-81e2-fb37ac552bad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm handler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dd3c462-136a-44cf-86ee-98f515626309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.mar [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  1.2 KiB/  1.2 KiB]                                                \n",
      "Operation completed over 1 objects/1.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp model.mar gs://text-to-image-model-429503/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29960e5-f74d-489d-beef-818e920d04a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchserve in /opt/conda/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: torch-model-archiver in /opt/conda/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from torchserve) (11.0.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from torchserve) (5.9.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchserve) (24.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from torchserve) (0.44.0)\n",
      "Requirement already satisfied: enum-compat in /opt/conda/lib/python3.10/site-packages (from torch-model-archiver) (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchserve torch-model-archiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dba5cf2-b414-44f4-a43e-6ac81546873d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java not found, please make sure JAVA_HOME is set properly.\n"
     ]
    }
   ],
   "source": [
    "!torchserve --start --model-store model_artifacts/model --models model=sdft.mar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "111804a8-4b29-40a9-b333-d5ae2525dcbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/optimizer.bin [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/optimizer.bin...  \n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/random_states_0.pkl [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/random_states_0.pkl...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/scaler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/scaler.pt...      \n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/scheduler.bin [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/scheduler.bin...  \n",
      "\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet/config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/unet/config.json...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet/diffusion_pytorch_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/unet/diffusion_pytorch_model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet_ema/config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/unet_ema/config.json...\n",
      "Copying gs://text-to-image-model-429503/model/checkpoint-500/unet_ema/diffusion_pytorch_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/checkpoint-500/unet_ema/diffusion_pytorch_model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/feature_extractor/preprocessor_config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/feature_extractor/preprocessor_config.json...\n",
      "Copying gs://text-to-image-model-429503/model/logs/text2image-fine-tune/1732728687.3225884/events.out.tfevents.1732728687.5d19749c37f3.259.1 [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/logs/text2image-fine-tune/1732728687.3225884/events.out.tfevents.1732728687.5d19749c37f3.259.1...\n",
      "Copying gs://text-to-image-model-429503/model/logs/text2image-fine-tune/1732728687.324261/hparams.yml [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/logs/text2image-fine-tune/1732728687.324261/hparams.yml...\n",
      "Copying gs://text-to-image-model-429503/model/logs/text2image-fine-tune/events.out.tfevents.1732728687.5d19749c37f3.259.0 [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/logs/text2image-fine-tune/events.out.tfevents.1732728687.5d19749c37f3.259.0...\n",
      "Copying gs://text-to-image-model-429503/model/model_index.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/model_index.json...              \n",
      "Copying gs://text-to-image-model-429503/model/safety_checker/config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/safety_checker/config.json...    \n",
      "Copying gs://text-to-image-model-429503/model/safety_checker/model.safetensors [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/safety_checker/model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/scheduler/scheduler_config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/scheduler/scheduler_config.json...\n",
      "Copying gs://text-to-image-model-429503/model/text_encoder/config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/text_encoder/config.json...      \n",
      "Copying gs://text-to-image-model-429503/model/text_encoder/model.safetensors [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/text_encoder/model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/merges.txt [Content-Type=text/plain]...\n",
      "Removing gs://text-to-image-model-429503/model/tokenizer/merges.txt...          \n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/special_tokens_map.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/tokenizer/special_tokens_map.json...\n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/tokenizer_config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/tokenizer/tokenizer_config.json...\n",
      "Copying gs://text-to-image-model-429503/model/tokenizer/vocab.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/tokenizer/vocab.json...          \n",
      "Copying gs://text-to-image-model-429503/model/unet/config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/unet/config.json...              \n",
      "Copying gs://text-to-image-model-429503/model/unet/diffusion_pytorch_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/unet/diffusion_pytorch_model.safetensors...\n",
      "Copying gs://text-to-image-model-429503/model/vae/config.json [Content-Type=application/json]...\n",
      "Removing gs://text-to-image-model-429503/model/vae/config.json...               \n",
      "Copying gs://text-to-image-model-429503/model/vae/diffusion_pytorch_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model/vae/diffusion_pytorch_model.safetensors...\n",
      "\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "|\n",
      "Operation completed over 26 objects/17.5 GiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil mv gs://text-to-image-model-429503/model gs://text-to-image-model-429503/model_artifacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f48ecf78-3366-49e8-b27b-5837eb23a357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://text-to-image-model-429503/model.mar [Content-Type=application/octet-stream]...\n",
      "Removing gs://text-to-image-model-429503/model.mar...                           \n",
      "\n",
      "Operation completed over 1 objects/1.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil mv gs://text-to-image-model-429503/model.mar gs://text-to-image-model-429503/model_artifacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8e8c317-9bf6-48a1-982b-6b6ee7ea3996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PYTORCH_PREDICTION_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.1-12:latest\"\n",
    ")\n",
    "APP_NAME = \"stable-diffusion-finetune\"\n",
    "VERSION = 1\n",
    "MODEL_DISPLAY_NAME = \"stable-diffusion-finetune\"\n",
    "MODEL_DESCRIPTION = \"finetuned stable_diffusion_1_4\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"{APP_NAME}-endpoint\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b1284e2-5719-44ba-a046-7457276019f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f5b61a2-e3b4-42fe-86de-4c13ec9e963c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.71.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.36.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.10.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3890ecda-066b-4d2a-8ef5-53e67dcc6b39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/684086472873/locations/us-central1/models/4029337381357223936/operations/3768473196785827840\n",
      "Model created. Resource name: projects/684086472873/locations/us-central1/models/4029337381357223936@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/684086472873/locations/us-central1/models/4029337381357223936@1')\n",
      "stable-diffusion-finetune\n",
      "projects/684086472873/locations/us-central1/models/4029337381357223936\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    description=MODEL_DESCRIPTION,\n",
    "    serving_container_image_uri=PYTORCH_PREDICTION_IMAGE_URI,\n",
    "    artifact_uri=FULL_GCS_PATH,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ed665ec-5d62-4a4e-b0b6-f06ade0f181c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/684086472873/locations/us-central1/endpoints/9125006428099051520/operations/5064946939515109376\n",
      "Endpoint created. Resource name: projects/684086472873/locations/us-central1/endpoints/9125006428099051520\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/684086472873/locations/us-central1/endpoints/9125006428099051520')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6110f-98da-48eb-8dec-b6b1baa2ebd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871b14b-809a-44fb-9876-ed3cb023bcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud ai endpoints describe 8044705467483553792 \\\n",
    "    --region=us-central1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e3d01-1b27-40ff-bd4f-f3028dced7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = aiplatform.Model('projects/684086472873/locations/us-central1/models/2576926501530238976@1')\n",
    "# endpoint = aiplatform.Endpoint('projects/684086472873/locations/us-central1/endpoints/4824631733913649152')\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_P100\",\n",
    "    accelerator_count=1,\n",
    "    deploy_request_timeout=5000,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062fba8-20d7-401b-b06e-bc69e77553b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
